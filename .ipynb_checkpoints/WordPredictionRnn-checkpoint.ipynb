{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c4fb7653-4f9f-4a8f-90fe-628d8273bff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c684e759-e753-46b3-b7d6-450699a6cfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "with open(\"./tiny_tiny_shakespere.txt\" ) as f:\n",
    "    text = f.read()\n",
    "tokens = text.lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af8abca9-9b8d-4756-9f29-b828ab414ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3bb951d1-0841-4ffb-a72f-63db55f59114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 9, 276, 26, 129, 130]\n"
     ]
    }
   ],
   "source": [
    "sequences = []\n",
    "window_size = 5  # number of input words\n",
    "\n",
    "encoded = tokenizer.texts_to_sequences([text])[0]\n",
    "\n",
    "for i in range(window_size, len(encoded)):\n",
    "    seq = encoded[i-window_size:i+1]   # previous N words + next word\n",
    "    sequences.append(seq)\n",
    "\n",
    "print(sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dfa95f7b-17b0-494c-aae7-d40bc0105e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max(len(seq) for seq in sequences)\n",
    "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "22f01692-0dee-4883-b12d-4bf44d3a79b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = sequences[:,:-1], sequences[:,-1]\n",
    "y = to_categorical(y, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "03a74179-74fd-4082-b73f-bc12e92cdd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data: 80% train, 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1737fc93-59c8-42bb-a270-0461bc9a58ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1d2cefa4790>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "mlp.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "mlp.fit(X_train, y_train, epochs=200, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a0faaab7-1635-4af7-878e-70995757c17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Accuracy: 0.02053388090349076\n"
     ]
    }
   ],
   "source": [
    "pred_probs = mlp.predict(X_test)\n",
    "y_pred = np.argmax(pred_probs, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)  # convert one-hot back to integers\n",
    "accuracy = np.mean(y_true == y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8148a125-201e-459a-8e71-adb92b76fe27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1d2cdf07090>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# RNN model (vanilla RNN)\n",
    "rnn = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, 50, input_length=X.shape[1]), # Embedding converts each word ID into a dense vector of features (e.g., 50-dim). words with similar contexts get similar embeddings.\n",
    "    tf.keras.layers.SimpleRNN(100),   # <- plain RNN here\n",
    "    tf.keras.layers.Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "rnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "rnn.fit(X_train, y_train, epochs=100, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "21fb832e-4b57-4cf3-ad29-e42bdffe8ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Accuracy: 0.006160164271047228\n"
     ]
    }
   ],
   "source": [
    "pred_probs = rnn.predict(X_test)\n",
    "y_pred = np.argmax(pred_probs, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)  # convert one-hot back to integers\n",
    "accuracy = np.mean(y_true == y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4740ecaa-a535-4850-9141-1a8723c338b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(model, tokenizer, text_seq, max_len):\n",
    "    encoded = tokenizer.texts_to_sequences([text_seq])[0]\n",
    "    \n",
    "    encoded = pad_sequences([encoded], maxlen=max_len-1, padding='pre')\n",
    "    \n",
    "    y_pred = model.predict(encoded, verbose=0).argmax()\n",
    "    \n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == y_pred:\n",
    "            return word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0fda4b13-f506-48b0-9531-57b6fbfb8952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more the the hunt own whether well thither flatter broke and and\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"No more\"\n",
    "next_word = \"\"\n",
    "for i in range(10):\n",
    "    next_word = predict_next_word(mlp, tokenizer, seed_text + next_word, max_len)\n",
    "    seed_text += \" \" + next_word\n",
    "\n",
    "print(seed_text, next_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2efd92aa-0a3a-48c7-b555-1fcb6c1a5dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more for for to speak it what very speak first bread bread\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"No more\"\n",
    "next_word = \"\"\n",
    "for i in range(10):\n",
    "    next_word = predict_next_word(rnn, tokenizer, seed_text + next_word, max_len)\n",
    "    seed_text += \" \" + next_word\n",
    "\n",
    "print(seed_text, next_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88543d83-4924-4b40-b30f-ead8da68e473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cd50c3-bd15-4be2-b33f-446cc17d8f15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
