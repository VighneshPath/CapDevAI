{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0d682c2-4cd0-4db7-869a-6ff2047c78d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Lowercase everything\n",
    "    text = text.lower()\n",
    "\n",
    "    # Keep only letters and basic punctuation\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s.,!?']\", \" \", text)\n",
    "\n",
    "    # Collapse multiple spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    # Tokenize into words\n",
    "    words = text.split()\n",
    "\n",
    "    vocab = sorted(set(words))\n",
    "    word2idx = {w:i for i,w in enumerate(vocab)}\n",
    "    idx2word = {i: w for w, i in word2idx.items()}\n",
    "    \n",
    "    return words, vocab, word2idx, idx2word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "430df785-7cd1-4d1b-9c55-0b753238bb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"\"\n",
    "with open(\"harrypotter.txt\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "\n",
    "words, vocab, word2idx, idx2word = preprocess_text(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08e3f51c-fb57-4ab6-9a82-8b67f17b3567",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# We’ll use 3 words to predict the next one\n",
    "seq_len = 3\n",
    "\n",
    "# Build training pairs: (input words → next word)\n",
    "data = []\n",
    "for i in range(len(words) - seq_len):\n",
    "    X = [word2idx[w] for w in words[i:i+seq_len]]   # e.g. [once, upon, a]\n",
    "    y = word2idx[words[i+seq_len]]                  # e.g. \"time\"\n",
    "    data.append((torch.tensor(X), torch.tensor(y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73e8ef00-d65c-4a5e-b8bb-67ca05bc71e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(data)\n",
    "split = int(0.8 * len(data))\n",
    "train_data = data[:split]\n",
    "val_data   = data[split:]\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "vocab_size = len(vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b4db2fd-dd60-40b4-9cca-72bffeb20090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f105e107-1973-4823-a461-be311f03a959",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, 16)        # turn words → vectors\n",
    "        self.rnn = nn.LSTM(16, 32, batch_first=True)     # process sequence\n",
    "        self.fc = nn.Linear(32, vocab_size)              # predict next word\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)                # [batch, seq, embed]\n",
    "        out, _ = self.rnn(x)             # [batch, seq, hidden]\n",
    "        last = out[:, -1, :]             # take the last output\n",
    "        return self.fc(last)             # predict next word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9d5e578-24b8-4ece-b633-f5bf1d0d5570",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, 16)\n",
    "        layer = nn.TransformerEncoderLayer(d_model=16, nhead=2, batch_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(layer, num_layers=2)\n",
    "        self.fc = nn.Linear(16, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        out = self.encoder(x)\n",
    "        last = out[:, -1, :]             # last token’s info\n",
    "        return self.fc(last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f07598d-17de-4824-940d-b4c9d2a3fd5a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyplot'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain\u001b[39m(model, name, epochs=\u001b[32m1\u001b[39m):\n\u001b[32m      3\u001b[39m     model = model.to(device)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pyplot'"
     ]
    }
   ],
   "source": [
    "import pyplot as plt\n",
    "def train(model, name, epochs=1):\n",
    "    model = model.to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        total_loss = 0\n",
    "        for X, y in train_data:\n",
    "            X, y = X.unsqueeze(0).to(device), y.to(device)\n",
    "            opt.zero_grad()\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y.unsqueeze(0))\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total_loss += loss.item()\n",
    "        train_loss = total_loss / len(train_data)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Validation\n",
    "        total_val = 0\n",
    "        with torch.no_grad():\n",
    "            for X, y in val_data:\n",
    "                X, y = X.unsqueeze(0).to(device), y.to(device)\n",
    "                pred = model(X)\n",
    "                loss = loss_fn(pred, y.unsqueeze(0))\n",
    "                total_val += loss.item()\n",
    "        val_loss = total_val / len(val_data)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        if epoch % 20 == 0:\n",
    "            print(f\"{name} epoch {epoch} | train {train_loss:.3f} val {val_loss:.3f}\")\n",
    "\n",
    "    # Plot losses\n",
    "    plt.plot(train_losses, label='train')\n",
    "    plt.plot(val_losses, label='val')\n",
    "    plt.title(f'{name} Loss per Epoch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bf4f8e1-781a-4e90-b204-168c122082a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, text_prefix):\n",
    "    model.eval()\n",
    "    words_in = re.findall(r\"\\w+\", text_prefix.lower())[-seq_len:]\n",
    "    X = torch.tensor([[word2idx[w] for w in words_in]]).to(device)\n",
    "    with torch.no_grad():\n",
    "        pred = model(X).argmax(-1).item()\n",
    "    print(f\"{text_prefix} ➜ {idx2word[pred]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "447d19ee-4fb6-485c-92e2-3a0c489ce394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN epoch 0 | train 9.219 val 9.431\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m rnn = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRNNModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mRNN\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, name, epochs)\u001b[39m\n\u001b[32m     35\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | train \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m val \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# Plot losses\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[43mplt\u001b[49m.plot(train_losses, label=\u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     39\u001b[39m plt.plot(val_losses, label=\u001b[33m'\u001b[39m\u001b[33mval\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     40\u001b[39m plt.title(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Loss per Epoch\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "rnn = train(RNNModel(), \"RNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dca0c70-42d3-47b1-8b6f-d0326ccc617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = train(TransformerModel(), \"Transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf345e5-3a09-42dc-858b-cf3cbdfc2b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\nPredictions:\")\n",
    "predict(rnn, \"once upon a\")\n",
    "predict(transformer, \"once upon a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398a1fa2-45d7-4a42-9e85-e99a1c0c629d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "torch.save(rnn.state_dict(), \"rnn_model.pth\")\n",
    "torch.save(transformer.state_dict(), \"transformer_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50859bdb-33f8-43b6-824b-2517354a9225",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load later\n",
    "rnn_loaded = RNNModel()\n",
    "rnn_loaded.load_state_dict(torch.load(\"rnn_model.pth\"))\n",
    "rnn_loaded.to(device)\n",
    "rnn_loaded.eval()\n",
    "\n",
    "transformer_loaded = TransformerModel()\n",
    "transformer_loaded.load_state_dict(torch.load(\"transformer_model.pth\"))\n",
    "transformer_loaded.to(device)\n",
    "transformer_loaded.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbfa5d7-82b1-40c2-9e42-553e453c69a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b884117-39f4-4dc9-8690-006d6b81aa69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db115950-eb77-43ae-96ea-214c7e110cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d52d0e-2fd3-4fdf-8fe6-ea3f11e8c81d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3fb5e3-4cfe-458a-9a7c-78611745fe07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a818a045-828a-443c-b696-49887ba32d61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30ef94d-106b-4480-b35f-b252efa57052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15346fab-c9ef-4781-ab6e-17fdf41cc0e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82444bf1-4f33-459d-9f0d-bf2b54c923db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f52e9e7-525e-40e7-80f5-3a62f07e6dff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
